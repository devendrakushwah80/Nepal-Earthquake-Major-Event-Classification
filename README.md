# ğŸŒ Nepal Earthquake Major Event Classification  
*(Using Nepal Seismic Data)*

## ğŸ“Œ Project Overview

Earthquakes vary significantly in their **severity and impact**.  
Early identification of **major earthquakes** can help in better risk assessment and preparedness.

In this project, the goal is to **predict whether an earthquake is a major event or not** using spatial, temporal, and historical seismic features from **Nepal seismicity data**.

The problem is formulated as a **binary classification task**, where machine learning models learn patterns associated with major seismic events.

---

## ğŸ“Š Dataset Description

The dataset consists of **historical earthquake records from Nepal** with the following features:

- **Spatial features:**  
  Latitude, Longitude, Location Offsets  

- **Seismic features:**  
  Magnitude, Rolling earthquake counts, Rolling mean magnitude  

- **Temporal features:**  
  Year, cyclical month and hour encodings  

- **Event history features:**  
  Days since last major earthquake  

- **Metadata:**  
  Data source  

---

## ğŸ¯ Target Variable

### `is_major` (Binary Classification Target)

- `0` â†’ Non-major earthquake  
- `1` â†’ Major earthquake  

> âš ï¸ To avoid **data leakage**, features directly derived from the target definition were carefully reviewed.

---

## ğŸ” Exploratory Data Analysis (EDA)

Key analyses performed:

- Dataset shape, data types, and memory usage
- Class distribution analysis of `is_major`
- Missing value and duplicate checks
- Feature-wise distributions
- Relationship between magnitude, time, and major earthquake occurrence
- Temporal patterns of major events

---

## ğŸ› ï¸ Data Preprocessing

The following preprocessing steps were applied:

- Dropped non-informative or high-cardinality columns:
  - `place`
  - raw datetime (`dt`)
- Removed depth-related columns to keep the task focused on classification:
  - `depth`
  - `depth_log`
- Label Encoding for categorical feature (`source`)
- Trainâ€“Test split using **80/20 ratio**
- Feature scaling using **StandardScaler**
- Ensured consistent preprocessing across train and test sets

---

## ğŸ¤– Machine Learning Models

Multiple **binary classification models** were implemented and compared:

### 1ï¸âƒ£ Logistic Regression
- Linear baseline classifier
- Interpretable coefficients
- Probability-based predictions
- Evaluated using ROCâ€“AUC

### 2ï¸âƒ£ K-Nearest Neighbors (KNN)
- Tested across multiple values of **K**
- Best K selected based on validation performance
- Demonstrates importance of feature scaling

### 3ï¸âƒ£ Support Vector Machine (SVM)
- Kernel-based classifier (RBF kernel)
- Handles non-linear decision boundaries
- Probability estimates enabled for ROCâ€“AUC comparison

---

## ğŸ“ˆ Model Evaluation

Models were evaluated using:

- Accuracy
- Precision, Recall, and F1-score
- ROCâ€“AUC Score
- Confusion Matrix

> Since **major earthquakes are relatively rare**, ROCâ€“AUC and Recall were emphasized over accuracy.

---

## ğŸ† Model Comparison Summary

| Model                | Accuracy | ROCâ€“AUC |
|---------------------|----------|---------|
| Logistic Regression | âœ“        | âœ“       |
| KNN                 | âœ“        | âœ“       |
| SVM                 | âœ“        | âœ“       |

*(Exact scores may vary depending on random state and preprocessing.)*

---

## ğŸ§  Key Learnings

- Major earthquake prediction is a **challenging and imbalanced classification problem**
- Temporal and historical seismic features add strong predictive value
- Feature scaling is crucial for KNN and SVM
- ROCâ€“AUC is a more reliable metric than accuracy for rare events
- Avoiding **data leakage** is critical for building realistic models

---

## ğŸ§¾ Requirements

```txt
pandas
numpy
matplotlib
seaborn
scikit-learn
